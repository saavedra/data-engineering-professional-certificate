In the previous video, you've learned
about the core components of grade expectations and what a typical
validation workflow looks like. Let's now apply these steps on an example
dataset, which is the DVD rental Database, you've seen in one of the labs
of week one of this course. We'll just focus on checking
the columns of the payment table. In particular, we'll check if the payment
id column contains unique ids, the customer id column does
not contain null values, and all the values in the amount
column are non-negative. I already set up a postgresSQL
database locally in my machine and loaded the data into the database. In the terminal I'll pip
install great expectations. Then, to start the great
expectations project, I'll type great expectations init. This command will initialize
the data context object, set up the structure of your
project folder as shown here, and create your backend stores such
as the checkpoints, expectations, data docs, and
validation stores as local directories. I'll type Y to proceed, you can always change the location
of your backend stores. So for example, in the lab you will
configure your stores as s three buckets. In this video ill keep
these as local directories. Now, to interact with the components of
great expectations, I'll launch a Jupyter notebook in the same root directory and
create this notebook file, example. Here in the notebook file, I'll first
import the great expectations package and then call the method get context,
to get the context object of the project. Using this object, you can connect to
the data source, define your expectations, create a validator, and
then run your checkpoints. So let's use this context to first
create the data source object. Create expectations provides different
methods that allow you to connect to your different data sources. To connect to my local SQL database, I'll
call the method context sources add sql, and then choose my datasource
as the name for the data source. This method also expects a connection
string that includes the information needed to connect to the database,
such as the username, password, hostname, port number, and the name of the database. Here's the format of the string that
you can use to connect to a postgresql database. Using this format, I'll create
the connection string to my database using the information of my local database. Next, from the data source, I'll create the data asset by
calling the method add tableasset. Since we're only focusing on the payment
table, I'll choose the name for the asset as payment tb and then specify the name of the table within
the source database, which is payment. In this case. Now, if you want to create batches on your
asset, great expectations provides a set of methods that allows you to split
your data asset based on the date or a column value. So for example, I'll call here the method
add splitter datetime part on the asset that I just created, and then indicate the
name of the column that contains the date, which is payment date, and specify month
for the second argument datetime parts. And finally, I'll create the batch request
object by calling the method build batch request on the asset object. Before we proceed with the workflow,
let's take a quick look at the batches. Using the asset object, I'll call the
method get batch list from batch requests and pass in the batch request
object I just created and then iterate over the batches to check
the specification of each batch. You can see the data contains four batches
where each batch corresponds to one month. Now that we have the batch request object
created, let's define the expectations. I'll do that interactively by
directly working with a validator. First, I will create the expectation
suite which will contain all the expectations that it will define. On the context object I'll
call the method add or update expectation suite and
choose the name mysuite. Now, to create the validator, I'll use the context object to
call the method get validator and pass in the batch request object and
the name of the expectation suite. Now, using the validator, you can call any of the expectation
methods from the expectation gallery. So here I'll call expect column
values to be unique to check the uniqueness of values
within the column payment id. The results are shown here,
correspond to the last batch. However, all batches were tested and
since we reached the last batch, it means the test ran successfully
on all the other batches. I'll now define two more expectations. Expect column values to not be null on
the column customer id to check that the column does not contain
any null values, and expect column min to be between on the
column amount to check that all values in the column are null negative. You can see that both
tests run successfully. Now these three expectations that I
created interactively while working with the validator are just available for
this session. In order to use these expectations in
other sessions, you need to save them. Using the validator, I'll call the method
save expectation suite and specify for great expectations to not
discard failed expectations, this method saves the expectation suite, my suite containing the three
expectations in the expectations store. Now, let's automate the process of the
validation using the checkpoint object. To create the checkpoint object,
I'll call the method add or update checkpoint on the context object
and assign the name mycheckpoint to it. This method expects validations as
a second argument which consists of a list of pairs of a data batch and
its corresponding expectation suite of to specify these validations I iterated
through the batches and for each batch I extracted the batch request and
used the name of the expectation suite. I'll now run the checkpoint
by calling the method run, the test on the four batches passed. To get more detailed information about
each result, you can check the data docs by calling the method build data
docs using the context object. This method returns a link that I'll
open to check out the data docs. Here you can find the results of
the validations performed on each batch. You can see that all
tests were successful. If you click on any row, you can
find statistics about the evaluated expectations as well as the successful and
unsuccessful expectations. You can also find the expectations
performed on each column and the corresponding result. So let's click on show more info. Here you'll find some metadata about the
checkpoint execution and the batches used. Now, let's go back to the homepage and
click on the expectation suites tab. Here you can find information about
the expectation suite, my suite. And there you have it. You now know how to interact with the core
components of grade expectations. Now, it's your turn to practice
using great expectations and validate some data in the lab.