In the previous lab exercise, you
implemented testing to confirm that your expectations for data quality were
met within your data pipelines. There are also other ways to maintain
data quality expectations with your upstream stakeholders, including
using what's called a data contract. Let's go have a conversation with my
friend Chad Sanderson about how data contracts can help ensure that the quality
of the data from its source remains high. This is another optional video to give you
a chance to hear from an industry expert. But you can also feel free to skip
ahead to the last part of the week, where we hear from Morgan
about Amazon Cloudwatch, the observability tool you'll use
in the last lab of this week. How's it going, Chad? >> Hey, Joe, it's going well,
good to see you. >> Likewise, good to see you, man. Yeah, so we're here to talk
about data contracts today, and it's a topic that we're
covering in the course. And I figured you're leading the way
in terms of making data contracts, exposing the visibility to these
things to the greater community. So definitely appreciate that, and I think you're a great person
to talk to about data contracts. So for the learners of this course and
who don't know who you are, do you want to give a quick
intro about yourself? >> Sure, my name is Chad Sanderson. Currently, I'm the CEO of a data
infrastructure startup called Gable.ai. Prior to this,
I led the data platform team at a few different companies like Microsoft,
Convoy, Sephora. I've been an analyst, a data scientist,
data engineering manager. So lots of time around data and
all the problems that happen. >> Yeah, lots of problems here. So let's get into it, I mean,
so what is a data contract? >> So a data contract,
in its most simple form, is an interface for data,
it's an API for data. And the idea is that if you're
a software engineer and someone else is accessing your service
in some way, you provide an interface. You don't want them just to have raw
access into the code that you've written. You have documentation expectations around
that interface, SLAs, and so on and so forth. But in the data world,
that concept doesn't really exist. We extract data from data producers who
generate it from their applications or from Excel spreadsheets or
from Salesforce or SAP. We load that data into analytical
databases and notebooks, and we take hard dependencies
on these producers. And so when things change, there is
no contract between the producer and the consumer that dictates what can
change and how it can change and what the expectations are. And this violation of expectations is
ultimately what causes the majority of data quality issues. >> Yep, exactly, and so walk me
through life before data contracts. What was that like? And walk me through your experience of
setting data contracts up in your work. >> So what I've seen happen at
most companies is that, well, I think there's a couple of
different types of companies. I think company one is more of your old
school, centralized data organization, where you've got data
architects leading the way. They're thinking about data modeling and
ERDs and working with the DBA team all the way
down to the actual analyst team. And they're kind of like this
center of excellence, and they're responsible for setting up all
the ETL, setting up the architecture. And in that world, data contracts
are a little bit less necessary. Because the entire infrastructure
has been really built and overseen from the ground up to
serve a particular function. But in the sort of modern world of data,
in the cloud, where we have data lakes, and
with all these new ideas, we have more of a federated
approach to data ingestion, where software engineers can build
whatever services they want. Those services emit tons of data. We throw all the data into
a data lake somewhere, and then we have a data engineering
team that goes in and builds out processes of extraction and
loading that data into other systems. And this is what actually
creates the problem. You now have two groups of people, which is the producers that
are producing all this data and the consumers that are consuming all
the data and doing something with it. And these two sides are not
communicating with each other. And when the lack of
communication is present and the services are still changing all
the time, the only option is chaos. And this is what happens. And so, downstream data teams have
to build so much validation into their machine learning models and
their pipelines because they expect change, and
they expect breaking issues constantly. And when a data quality issue does emerge, the data engineering team has to
go down this root causing path. That takes a really long time. Someone who owns a dashboard is
complaining, then a metric looks off, throw it over the fence to
the data engineering team. Data engineering has to look at
that query and say, okay, well, what could all the potential causes be? They have to trace all the way
back up to the source. They have to understand what changed. They have to ask the producer to fix it. And then once that fix happens, then they
have to go in and do a whole backfilling process, and this has basically just
become the data engineering job. I think a lot of people would associate
data engineering with those set of steps that I just said. And I don't actually think that's what
the ideal data engineering job is. >> Right, yeah, it definitely seems to
be like that, it's certainly been my experience, too, that we are at
the mercy of the producers, typically. And oftentimes, you're at the mercy
of their whims and changes, and when things break,
you get to go clean it up. And that's about has been. But along come data contracts. And I'm sure one question the learners
of this course will have is, what does this interface of
a data contract look like? How do I work with the data contract? What exactly does it
feel like to use this? >> So the interface is what we call
the spec of the data contract. And I think at a high level,
there's a couple different components to a contract itself, one is the spec,
which is very similar to an API spec. It's like swagger, if you've done any
work with actually creating APIs, and then on the other side you have
your mechanism of enforcement. How do we ensure that that spec is
followed and that if violations happen, you have some way of actually
recording and tracking that. But in terms of what the spec looks like, it's generally composed
of two main categories. You could extend it as infinitely long,
but the primary categories are the structure of the data object and
the contents of the data. And on the structural side,
you have the schema and the business logic that
ultimately composes the schema. Those are things like column names and
the number of columns that exist and the actual logic, composing the columns. And then on the data content side, that's
where you have your data quality rules, SLAs, PII, these sorts of things. And you might layer on additional
policies like compliance. Like this is the way we expect
the data to always be used. Or, if someone is writing
a query against this data, it should follow a certain format. So that's what goes into the contract,
it's really infinitely extensible. But my recommendation is always to make
sure that all of the constraints within the contract are actionable and
are enforceable. Otherwise, it kind of just becomes
a paper handshake agreement. >> And you mentioned handshake agreement,
for example, right? So I think, implicit to the word contract, there's maybe some interpretation that
this data contract might be sort of some legally binding agreement or
a handshake deal with teams. How do you respond to things like that? I guess it's the follow on to this, how much of a data contract is
communication versus technology? >> Yeah, I think that's a great question. So I definitely think it's not
a legal contract, it could be. In fact, I have heard examples of teams
that want to have legally binding data contracts with vendors. So if you're agreeing to pay
a certain amount of money for data, that's always supposed to be
a certain way, and then it isn't, and that has a material
impact on your company. That is maybe something you
want to get a lawyer for. But if you're operating within a company,
there's really no, it wouldn't even be a good idea to take legal
action against another team internally. So oftentimes is that
the contract enforcement is more about the programmatic
nature of that enforcement. Integration tests, as an example,
are a form of enforcement. Or alerts and monitors that are sent to
the people who are consuming the data to make them aware that a contract breach has
occurred is another form of enforcement. And then, on the question of how
much of this is collaboration and people, I think it's primarily people. The technology part really is all
about making the process of adopting the contract,
agreeing to the contract, and then taking action on the contract very,
very easy. One of the common patterns that I've seen
a lot is that data engineers will attempt to solve this problem by asking
the application developers to own data engineering processes. So here's a set of tables that you now
own as the software engineering team, or we would like for you to own a DBT. And generally, this doesn't go very well, because application developers don't know
anything about Snowflake or DBT, and it's seen as a cost and a burden on
their time, and it slows them down. No software engineer
wants to be slowed down. The way that technology helps in
this problem is it allows the data contract to be implemented and enforced in the workflow that
the developer is already using. And it makes the honoring
of that contract trivial. This is something that we've
actually seen in other industries. So security has followed a very
similar pattern where you had a very small team of security engineers,
not very many of them in an organization, they had a lot of surface
area to think about, and they were at the mercy of the application
developers to do the right thing. And Devsecops is this emerging pattern
where instead of hoping that everyone in the company follows security best
practices, you have a layer of technology that is sitting in the DevOps workflow
that's doing the check against the code and saying, hey, is the code that we're
shipping following these best practices? And if not, there's communication that
needs to go out to the right people. >> What else should the learner
know about data contracts? And also, I think a follow on question is,
if they wanted to implement data contracts, how could they get started
with that in terms of what's to know, I think there's a lot of different
ways you can implement the contract. >> Some of these will be more
likely to succeed than others. I think going in with the idea that we're
going to create a massive contract and it will have all of these, a million
different constraints, and we'll give this to the software engineer and they won't
have any technology that actually allows them to own the contract is a very good
way for people to not take you seriously. It will seem like a lot of work and it
will be very scary and it won't be clear how they will incorporate this
into their existing processes. So I think you need to have a good answer
to that before you go to the producer and have the conversation. The other thing I think is important is, software engineers like
working on things that matter. And really, anybody does, I think, you don't want to do random
work that is irrelevant. And I've seen some teams that will go to
their engineering counterparts and say, hey, guys, you need to own all of the data
that you're emitting from your services. Even if only 10% of that data
is useful to the analytics team, that becomes a weird question. It's like, well, why are you asking me to own 100% of
this if you're only using 10% of that? You're slowing me down,
making me think about schema evolution and all these other things, and
I don't really gain anything in return. I'm not doing anything for you. So I think being selective about where
you start with contracts and making sure you're focusing on the most important
pipelines, where there is a clear impact. If data quality were to go bad is
a really great starting point in terms of where you actually
begin with an implementation. Honestly, paper contracts and just having
the conversation is a really good start. Most of the data producers that
I talk to will say things like, I have no idea where my data is even being
used in the company, and it's hard for me to want to take ownership of that data
if I don't know what's happening to it. So just sort of overcoming that bridge and
saying, hey, engineering team A, did you know that your data is being
used in machine learning model X and dashboard Y that the CFO looks
at every single morning? Is a good way to start making them
aware of how data that's kind of a byproduct to them is
impacting the broader business. >> That's awesome, such awesome advice. Well, Chad, thank you for your time. I'm sure learners will get a lot out
of this discussion, so thank you. >> Thanks, Joe. >> Yeah, thanks.