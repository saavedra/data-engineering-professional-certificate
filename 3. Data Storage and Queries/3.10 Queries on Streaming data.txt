So far, we've been discussing how to query batch data, but as streaming data becomes more prevalent, you might find yourself needing to aggregate and join together streaming data as well. When querying your streaming data, you must adopt query patterns that reflect the real-time nature of this data. Let's say you want to ingest data from this streaming system and process a stream of data as soon as you receive it. You can use stream processing systems, such as Apache Flink and Spark Streaming, which enable you to apply SQL queries, even complex ones, continuously over your stream of data. Streaming platforms such as Kafka also support querying data in Kafka streams. With these systems, you can continuously aggregate the streaming data by applying something called a windowed query, which allows you to bound your queries using a window and then apply operations such as aggregation, adding, or removing data over that window. Let's take a look at three common types of windows, session, fixed time, and sliding windows. A session window is ideal for handling events that arrive at irregular times. It groups events that occur at similar times and filters out periods of time when there are no events. When using this type of window, you need to specify the maximum time gap allowed between events to identify when one session ends and another one begins. For example, let's say you're analyzing website clicks for each user and decide to set the time gap of an activity to be 5 minutes or more between your session windows. In here, you'll have three session windows because they are each separated by 5 minutes or more of user inactivity. Note that session windows are unique to each key, so in this example, each user gets their own set of session windows. Doing analytics on these windows could, for example, allow an analyst to do something like follow up with an email that has a coupon for a product that was viewed by the user in their last session window. To determine the session boundaries, the processing system starts with a new session window when the first event occurs. In this case, the first website clicked by a user. Then the system continues to accumulate arriving events for that user, as long as no events happen within 5 minutes of the previous one. Once there's a 5 minute inactivity period, the system closes the window, sends the consumer any specified aggregations like max, min, or average values, and then flushes the data. If no events for the user arrive later, the system starts a new session window. And so with session windows, the windows can extend to be of any size as long as events keep on arriving close to each other. Alternatively, you could aggregate the data for events over windows of fixed size, known as fixed time or tumbling windows. For example, here you have 3 fixed time windows, each lasting 20 seconds. The system processes all data arriving within each window, and then sends the aggregations as soon as the window is closed. This can be useful if you like to compute, for example, the total number of clicks that happen every 20 seconds. This is similar to traditional batch ETL processing, where you might run a data update job every day or every hour. However, the streaming processing system allows you to generate windows more frequently and deliver results with lower latency. With session and fixed time windows, the windows are non-overlapping. But with sliding windows, you can group events into windows of fixed time length that can overlap. For example, here you have 3 60 second overlapping windows generated every 30 seconds. This type of windowing can help you calculate things like a moving average within a time interval. In addition to aggregating streams of data, you can also join multiple streams, or combine a stream with batch historical data. The conventional way of joining multiple data streams is to transform each stream into a table and then join the tables in the database. But streaming processing systems are increasingly supporting direct stream-to-stream joining. So for example, you might want to join a stream of web browsing data with streaming data from an ad platform. Since those streams can be produced at different event rates and have different latencies, typical streaming join architectures rely on streaming buffers that can retain those events for a certain period of time. Events from the streams get joined in the buffer and are eventually emitted after the buffer's retention period passes. Aside from joining two streams of data, you might also want to join streaming data with batch historical data that's stored in a database or object storage in order to produce an enriched stream of events. For example, you might want to enrich product browsing events from an e-commerce website with product details and user demographic information. To do this, you might use a serverless function or a processing system to look up the product and user information in an in-memory database or object storage, then add the required information to the event, and finally output the enhanced events to another stream. For the last slab of this week, you'll work with the streaming data that you saw back in course 1. But now you'll apply time-based windowed queries to process this data. In the next video, Morgan will give you an overview of the Amazon Managed Service for Apache Flink that you'll use to accomplish this.